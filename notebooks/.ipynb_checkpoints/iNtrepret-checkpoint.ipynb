{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T19:29:33.208670Z",
     "start_time": "2019-06-18T19:29:33.199404Z"
    }
   },
   "outputs": [],
   "source": [
    "from Obtain import pickle_to, pickle_from\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "def identity(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To ignore warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T19:29:36.372150Z",
     "start_time": "2019-06-18T19:29:36.359530Z"
    }
   },
   "outputs": [],
   "source": [
    "if not sys.warnoptions:\n",
    "    import os, warnings\n",
    "    warnings.simplefilter(\"ignore\") # Change the filter in this process\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"default\" # Also affect subprocesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpickling necessary objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:00:38.677407Z",
     "start_time": "2019-06-18T23:00:37.778546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file from X_train.pkl\n",
      "Loaded file from X_tr_val.pkl\n",
      "Loaded file from y_tr_val.pkl\n",
      "Loaded file from X_test.pkl\n",
      "Loaded file from y_test.pkl\n",
      "Loaded file from y_train.pkl\n"
     ]
    }
   ],
   "source": [
    "X_train = pickle_from(\"X_train.pkl\")\n",
    "X_tr_val = pickle_from('X_tr_val.pkl')\n",
    "y_tr_val = pickle_from('y_tr_val.pkl')\n",
    "X_test = pickle_from('X_test.pkl')\n",
    "y_test = pickle_from('y_test.pkl')\n",
    "y_train = pickle_from('y_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set\n",
    "\n",
    "Training the model on the entire training set and testing on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T22:32:03.393238Z",
     "start_time": "2019-06-18T22:32:00.907130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary='boolean', decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function <lambda> at 0x1a2244cbf8>, vocabulary=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_bool = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False,binary ='boolean')\n",
    "c_bool.fit(X_tr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T22:32:14.039619Z",
     "start_time": "2019-06-18T22:32:09.209450Z"
    }
   },
   "outputs": [],
   "source": [
    "X_tr_val_bool = c_bool.transform(X_tr_val)\n",
    "X_test_bool = c_bool.transform(X_test)\n",
    "\n",
    "X_tr_val_dense = X_tr_val_bool.todense()\n",
    "X_test_dense = X_test_bool.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T22:36:12.821162Z",
     "start_time": "2019-06-18T22:32:22.056597Z"
    }
   },
   "outputs": [],
   "source": [
    "logreg= LogisticRegressionCV(scoring='accuracy',max_iter = 1000)\n",
    "model = logreg.fit(X_tr_val_dense,y_tr_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T22:36:12.884446Z",
     "start_time": "2019-06-18T22:36:12.824242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully saved to model.pkl\n"
     ]
    }
   ],
   "source": [
    "pickle_to(model,'model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T22:51:25.265546Z",
     "start_time": "2019-06-18T22:37:09.871763Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-c8ffeb6caa44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tr_val_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy on train:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy on test:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1797\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m                       )\n\u001b[0;32m-> 1799\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1800\u001b[0m             for train, test in folds)\n\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[0;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                 iprint=iprint, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[1;32m    756\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m                 warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Case where we fit the intercept.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/metis/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tr_accuracy = np.mean(cross_val_score(model, X_tr_val_dense, y_tr_val,cv=10))\n",
    "val_accuracy = np.mean(cross_val_score(model, X_test_dense, y_test,cv=10))\n",
    "print('Accuracy on train:', tr_accuracy,'\\n', 'Accuracy on test:', val_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is performing with an accuracy of 88% in the test set!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T20:24:01.677270Z",
     "start_time": "2019-06-18T20:24:01.447297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON TEST SET\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute normalized confusion matrix\n",
    "y_pred = model.predict(X_test_dense)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cm_normalized = cnf_matrix.astype('float')/cnf_matrix.sum(axis=1)[:,np.newaxis]\n",
    "\n",
    "\n",
    "# name  of classes\n",
    "class_names=['Fake','Real'] \n",
    "\n",
    "# Set fig and axes \n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(pd.DataFrame(cm_normalized), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Normalized Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual',rotation=0)\n",
    "plt.xlabel('Predicted');\n",
    "\n",
    "print(\"ON TEST SET\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get top words in real news and fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T22:59:14.251010Z",
     "start_time": "2019-06-18T22:59:13.269567Z"
    }
   },
   "outputs": [],
   "source": [
    "c_bin = CountVectorizer(tokenizer=lambda doc: doc,lowercase=False, binary = 'boolean')\n",
    "c_bin_vectorizer = c_bin.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:00:44.798617Z",
     "start_time": "2019-06-18T23:00:42.419935Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_bin = c_bin_vectorizer.transform(X_train)\n",
    "X_train_bin = X_train_bin.toarray()\n",
    "feature_names = c_bin.get_feature_names()\n",
    "df_test = pd.DataFrame(X_train_bin)\n",
    "df_test.columns = feature_names\n",
    "idx = 0\n",
    "df_test.insert(loc = idx, column = 'labels',value = y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:00.261165Z",
     "start_time": "2019-06-18T23:00:46.898227Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fake = df_test.loc[df_test['labels'] == 0]\n",
    "df_fake = df_fake.T\n",
    "df_fake['fake_total'] = df_fake.sum(axis = 1)\n",
    "df_fake = df_fake.drop(df_fake.index[0])\n",
    "df_fake = df_fake['fake_total']\n",
    "df_fake = df_fake.sort_values(ascending=False)\n",
    "df_fake = df_fake.to_frame().reset_index()\n",
    "df_fake.rename(columns={\"index\": \"word\"},inplace = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:05.112023Z",
     "start_time": "2019-06-18T23:01:00.264718Z"
    }
   },
   "outputs": [],
   "source": [
    "df_real = df_test.loc[df_test['labels'] == 1]\n",
    "df_real = df_real.T\n",
    "df_real['real_total'] = df_real.sum(axis = 1)\n",
    "df_real = df_real.drop(df_real.index[0])\n",
    "df_real = df_real['real_total']\n",
    "df_real = df_real.sort_values(ascending=False)\n",
    "# df_real = df_real[:2500]\n",
    "df_real = df_real.to_frame().reset_index()\n",
    "df_real.rename(columns={\"index\": \"word\"},inplace = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:30.131786Z",
     "start_time": "2019-06-18T23:01:30.026430Z"
    }
   },
   "outputs": [],
   "source": [
    "df_both = pd.merge(df_real, df_fake, how='inner', on='word')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:30.687750Z",
     "start_time": "2019-06-18T23:01:30.628943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>real_total</th>\n",
       "      <th>fake_total</th>\n",
       "      <th>sub</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>rand</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>boehner</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>0.978495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>fiorina</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0.970588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>carly</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>gunman</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0.966102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>presumptive</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>0.961905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>rubio</td>\n",
       "      <td>251</td>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "      <td>0.960938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>mitch</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>frontrunner</td>\n",
       "      <td>196</td>\n",
       "      <td>4</td>\n",
       "      <td>192</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>marco</td>\n",
       "      <td>239</td>\n",
       "      <td>5</td>\n",
       "      <td>234</td>\n",
       "      <td>0.959016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>cruzs</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>0.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>rky</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.957447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>matchup</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>frontrunners</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>huckabee</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>0.943662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>polarization</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>cruz</td>\n",
       "      <td>333</td>\n",
       "      <td>13</td>\n",
       "      <td>320</td>\n",
       "      <td>0.924855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>trustworthy</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>kasich</td>\n",
       "      <td>171</td>\n",
       "      <td>7</td>\n",
       "      <td>164</td>\n",
       "      <td>0.921348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>loom</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>dogged</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>palin</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>kurtz</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>omalley</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>samesex</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>winnertakeall</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>touting</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>manhunt</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4491</th>\n",
       "      <td>hardliner</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4470</th>\n",
       "      <td>inroad</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>fan</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>initial</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>armed</td>\n",
       "      <td>107</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>crisis</td>\n",
       "      <td>162</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>short</td>\n",
       "      <td>166</td>\n",
       "      <td>163</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>hillary</td>\n",
       "      <td>667</td>\n",
       "      <td>655</td>\n",
       "      <td>12</td>\n",
       "      <td>0.009077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>supposed</td>\n",
       "      <td>112</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>outlet</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>scale</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>normal</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>cover</td>\n",
       "      <td>123</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>review</td>\n",
       "      <td>127</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>donation</td>\n",
       "      <td>69</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>currently</td>\n",
       "      <td>138</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>meaning</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>influence</td>\n",
       "      <td>144</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>conduct</td>\n",
       "      <td>75</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>account</td>\n",
       "      <td>161</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>billion</td>\n",
       "      <td>165</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>prove</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>danger</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>usually</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>territory</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>designed</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>radio</td>\n",
       "      <td>107</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>actually</td>\n",
       "      <td>321</td>\n",
       "      <td>318</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>necessary</td>\n",
       "      <td>121</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>finally</td>\n",
       "      <td>148</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>movement</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>life</td>\n",
       "      <td>456</td>\n",
       "      <td>455</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10191 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  real_total  fake_total  sub      perc\n",
       "1108  rand           111         1           110  0.982143\n",
       "1332  boehner        92          1           91   0.978495\n",
       "1775  fiorina        67          1           66   0.970588\n",
       "1832  carly          64          1           63   0.969231\n",
       "1977  gunman         58          1           57   0.966102\n",
       "1197  presumptive    103         2           101  0.961905\n",
       "408   rubio          251         5           246  0.960938\n",
       "1224  mitch          100         2           98   0.960784\n",
       "560   frontrunner    196         4           192  0.960000\n",
       "435   marco          239         5           234  0.959016\n",
       "1324  cruzs          93          2           91   0.957895\n",
       "2385  rky            46          1           45   0.957447\n",
       "2480  matchup        44          1           43   0.955556\n",
       "2964  frontrunners   35          1           34   0.944444\n",
       "1717  huckabee       69          2           67   0.943662\n",
       "2150  polarization   52          2           50   0.925926\n",
       "262   cruz           333         13          320  0.924855\n",
       "3822  trustworthy    25          1           24   0.923077\n",
       "670   kasich         171         7           164  0.921348\n",
       "3908  loom           24          1           23   0.920000\n",
       "3978  dogged         24          1           23   0.920000\n",
       "3909  palin          24          1           23   0.920000\n",
       "4024  kurtz          23          1           22   0.916667\n",
       "2417  omalley        46          2           44   0.916667\n",
       "1759  samesex        67          3           64   0.914286\n",
       "4300  winnertakeall  21          1           20   0.909091\n",
       "4311  touting        21          1           20   0.909091\n",
       "4502  manhunt        20          1           19   0.904762\n",
       "4491  hardliner      20          1           19   0.904762\n",
       "4470  inroad         20          1           19   0.904762\n",
       "...      ...         ..         ..           ..        ...\n",
       "2182  fan            52          51          1    0.009709\n",
       "2174  initial        52          51          1    0.009709\n",
       "1141  armed          107         105         2    0.009434\n",
       "716   crisis         162         159         3    0.009346\n",
       "699   short          166         163         3    0.009119\n",
       "59    hillary        667         655         12   0.009077\n",
       "1089  supposed       112         110         2    0.009009\n",
       "1935  outlet         60          59          1    0.008403\n",
       "1910  scale          61          60          1    0.008264\n",
       "1908  normal         61          60          1    0.008264\n",
       "981   cover          123         121         2    0.008197\n",
       "949   review         127         125         2    0.007937\n",
       "1713  donation       69          68          1    0.007299\n",
       "871   currently      138         136         2    0.007299\n",
       "1665  meaning        72          71          1    0.006993\n",
       "827   influence      144         142         2    0.006993\n",
       "1614  conduct        75          74          1    0.006711\n",
       "721   account        161         159         2    0.006250\n",
       "703   billion        165         163         2    0.006098\n",
       "1470  prove          83          82          1    0.006061\n",
       "1474  danger         83          82          1    0.006061\n",
       "1466  usually        84          83          1    0.005988\n",
       "1425  territory      86          85          1    0.005848\n",
       "1284  designed       96          95          1    0.005236\n",
       "1149  radio          107         106         1    0.004695\n",
       "275   actually       321         318         3    0.004695\n",
       "1005  necessary      121         120         1    0.004149\n",
       "801   finally        148         147         1    0.003390\n",
       "629   movement       178         177         1    0.002817\n",
       "140   life           456         455         1    0.001098\n",
       "\n",
       "[10191 rows x 5 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_both['sub'] = df_both['real_total'] - df_both['fake_total']\n",
    "df_both['perc'] = df_both['sub']/(df_both['real_total']+df_both['fake_total'])\n",
    "df_both.sort_values(by = 'perc',ascending = False)\n",
    "\n",
    "#Filtering words that come only once\n",
    "df_both = df_both[(df_both['perc'] > -1.0) & (df_both['perc'] < 1.0) & (df_both['perc'] != 0.000000) ]\n",
    "\n",
    "df_top_real = df_both[(df_both['perc'] > 0.000001)]\n",
    "df_top_fake = df_both[(df_both['perc'] < 0.000001)]\n",
    "df_top_real.sort_values(by='perc',ascending =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:35.465961Z",
     "start_time": "2019-06-18T23:01:35.441704Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>real_total</th>\n",
       "      <th>fake_total</th>\n",
       "      <th>sub</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30069</th>\n",
       "      <td>rt</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>-42</td>\n",
       "      <td>-0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21406</th>\n",
       "      <td>weiners</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>-33</td>\n",
       "      <td>-0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28745</th>\n",
       "      <td>pertinent</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>-27</td>\n",
       "      <td>-0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25078</th>\n",
       "      <td>indigenous</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>-26</td>\n",
       "      <td>-0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29454</th>\n",
       "      <td>podestas</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>-25</td>\n",
       "      <td>-0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28931</th>\n",
       "      <td>pictwittercom</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>-25</td>\n",
       "      <td>-0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29271</th>\n",
       "      <td>baltic</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>-24</td>\n",
       "      <td>-0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35752</th>\n",
       "      <td>paradigm</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>-23</td>\n",
       "      <td>-0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35888</th>\n",
       "      <td>oligarch</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-19</td>\n",
       "      <td>-0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31076</th>\n",
       "      <td>republish</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-19</td>\n",
       "      <td>-0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24033</th>\n",
       "      <td>euro</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-19</td>\n",
       "      <td>-0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34834</th>\n",
       "      <td>subscribing</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>-18</td>\n",
       "      <td>-0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21254</th>\n",
       "      <td>mar</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>-18</td>\n",
       "      <td>-0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28802</th>\n",
       "      <td>pesticide</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>-18</td>\n",
       "      <td>-0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28526</th>\n",
       "      <td>toxin</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>-18</td>\n",
       "      <td>-0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23272</th>\n",
       "      <td>globalists</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>-18</td>\n",
       "      <td>-0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28885</th>\n",
       "      <td>perpetual</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>-17</td>\n",
       "      <td>-0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19938</th>\n",
       "      <td>neocon</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>-34</td>\n",
       "      <td>-0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34201</th>\n",
       "      <td>msm</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>-17</td>\n",
       "      <td>-0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15501</th>\n",
       "      <td>soros</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>-51</td>\n",
       "      <td>-0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26725</th>\n",
       "      <td>imperialism</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>-16</td>\n",
       "      <td>-0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28415</th>\n",
       "      <td>radiation</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>-16</td>\n",
       "      <td>-0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24820</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>-16</td>\n",
       "      <td>-0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20125</th>\n",
       "      <td>navigation</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>-30</td>\n",
       "      <td>-0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35464</th>\n",
       "      <td>cc</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>-15</td>\n",
       "      <td>-0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28665</th>\n",
       "      <td>planetary</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>-15</td>\n",
       "      <td>-0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35233</th>\n",
       "      <td>totalitarian</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>-15</td>\n",
       "      <td>-0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35685</th>\n",
       "      <td>particle</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>-15</td>\n",
       "      <td>-0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22345</th>\n",
       "      <td>dy</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>-15</td>\n",
       "      <td>-0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22199</th>\n",
       "      <td>warmonger</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>-14</td>\n",
       "      <td>-0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>age</td>\n",
       "      <td>130</td>\n",
       "      <td>133</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.011407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>promoting</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.011236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>globe</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.010753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>convinced</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.010753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>recall</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.010753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>actual</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.010638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>whole</td>\n",
       "      <td>192</td>\n",
       "      <td>196</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.010309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>following</td>\n",
       "      <td>242</td>\n",
       "      <td>247</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.010225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>military</td>\n",
       "      <td>291</td>\n",
       "      <td>297</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>knowing</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>historical</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>recognized</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.009709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>child</td>\n",
       "      <td>258</td>\n",
       "      <td>263</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.009597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>resource</td>\n",
       "      <td>107</td>\n",
       "      <td>109</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.009259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>northern</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.008403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>murder</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.007634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>strategic</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.007519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>today</td>\n",
       "      <td>397</td>\n",
       "      <td>403</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>produce</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>include</td>\n",
       "      <td>149</td>\n",
       "      <td>151</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>racist</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.006452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>interesting</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.006211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>fear</td>\n",
       "      <td>175</td>\n",
       "      <td>177</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>attempt</td>\n",
       "      <td>181</td>\n",
       "      <td>183</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.005495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>science</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.005128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>confirmed</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.004484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>knew</td>\n",
       "      <td>115</td>\n",
       "      <td>116</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.004329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>quite</td>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.003390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>study</td>\n",
       "      <td>160</td>\n",
       "      <td>161</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>thought</td>\n",
       "      <td>258</td>\n",
       "      <td>259</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.001934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7398 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  real_total  fake_total  sub      perc\n",
       "30069  rt             1           43         -42  -0.954545\n",
       "21406  weiners        1           34         -33  -0.942857\n",
       "28745  pertinent      1           28         -27  -0.931034\n",
       "25078  indigenous     1           27         -26  -0.928571\n",
       "29454  podestas       1           26         -25  -0.925926\n",
       "28931  pictwittercom  1           26         -25  -0.925926\n",
       "29271  baltic         1           25         -24  -0.923077\n",
       "35752  paradigm       1           24         -23  -0.920000\n",
       "35888  oligarch       1           20         -19  -0.904762\n",
       "31076  republish      1           20         -19  -0.904762\n",
       "24033  euro           1           20         -19  -0.904762\n",
       "34834  subscribing    1           19         -18  -0.900000\n",
       "21254  mar            1           19         -18  -0.900000\n",
       "28802  pesticide      1           19         -18  -0.900000\n",
       "28526  toxin          1           19         -18  -0.900000\n",
       "23272  globalists     1           19         -18  -0.900000\n",
       "28885  perpetual      1           18         -17  -0.894737\n",
       "19938  neocon         2           36         -34  -0.894737\n",
       "34201  msm            1           18         -17  -0.894737\n",
       "15501  soros          3           54         -51  -0.894737\n",
       "26725  imperialism    1           17         -16  -0.888889\n",
       "28415  radiation      1           17         -16  -0.888889\n",
       "24820  wikipedia      1           17         -16  -0.888889\n",
       "20125  navigation     2           32         -30  -0.882353\n",
       "35464  cc             1           16         -15  -0.882353\n",
       "28665  planetary      1           16         -15  -0.882353\n",
       "35233  totalitarian   1           16         -15  -0.882353\n",
       "35685  particle       1           16         -15  -0.882353\n",
       "22345  dy             1           16         -15  -0.882353\n",
       "22199  warmonger      1           15         -14  -0.875000\n",
       "...          ...     ..           ..          ..        ...\n",
       "924    age            130         133        -3   -0.011407\n",
       "2509   promoting      44          45         -1   -0.011236\n",
       "2403   globe          46          47         -1   -0.010753\n",
       "2401   convinced      46          47         -1   -0.010753\n",
       "2399   recall         46          47         -1   -0.010753\n",
       "1312   actual         93          95         -2   -0.010638\n",
       "577    whole          192         196        -4   -0.010309\n",
       "428    following      242         247        -5   -0.010225\n",
       "328    military       291         297        -6   -0.010204\n",
       "2281   knowing        49          50         -1   -0.010101\n",
       "2225   historical     50          51         -1   -0.009901\n",
       "2194   recognized     51          52         -1   -0.009709\n",
       "387    child          258         263        -5   -0.009597\n",
       "1136   resource       107         109        -2   -0.009259\n",
       "1959   northern       59          60         -1   -0.008403\n",
       "1830   murder         65          66         -1   -0.007634\n",
       "1786   strategic      66          67         -1   -0.007519\n",
       "197    today          397         403        -6   -0.007500\n",
       "1625   produce        74          75         -1   -0.006711\n",
       "794    include        149         151        -2   -0.006667\n",
       "1573   racist         77          78         -1   -0.006452\n",
       "1524   interesting    80          81         -1   -0.006211\n",
       "652    fear           175         177        -2   -0.005682\n",
       "620    attempt        181         183        -2   -0.005495\n",
       "1263   science        97          98         -1   -0.005128\n",
       "1103   confirmed      111         112        -1   -0.004484\n",
       "1059   knew           115         116        -1   -0.004329\n",
       "810    quite          147         148        -1   -0.003390\n",
       "729    study          160         161        -1   -0.003115\n",
       "386    thought        258         259        -1   -0.001934\n",
       "\n",
       "[7398 rows x 5 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_fake.sort_values(by='perc',ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T18:23:22.238053Z",
     "start_time": "2019-06-18T18:23:00.449Z"
    }
   },
   "outputs": [],
   "source": [
    "performance = pickle_from('performance.pkl')\n",
    "tr_performance = pickle_from('tr_performance.pkl')\n",
    "val_performance = pickle_from('val_performance.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T19:34:17.641592Z",
     "start_time": "2019-06-18T19:34:17.629417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_performance</th>\n",
       "      <th>val_performance</th>\n",
       "      <th>diff</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.907173</td>\n",
       "      <td>0.906884</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.879612</td>\n",
       "      <td>0.870806</td>\n",
       "      <td>0.008806</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.811918</td>\n",
       "      <td>0.798568</td>\n",
       "      <td>0.013350</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.810595</td>\n",
       "      <td>0.767226</td>\n",
       "      <td>0.043369</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.579477</td>\n",
       "      <td>0.510426</td>\n",
       "      <td>0.069051</td>\n",
       "      <td>Support Vector Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train_performance  val_performance      diff  \\\n",
       "logreg  0.907173           0.906884         0.000289   \n",
       "gb      0.879612           0.870806         0.008806   \n",
       "nb      0.811918           0.798568         0.013350   \n",
       "rf      0.810595           0.767226         0.043369   \n",
       "svm     0.579477           0.510426         0.069051   \n",
       "\n",
       "                            model  \n",
       "logreg  Logistic Regression        \n",
       "gb      Gradient Boosting          \n",
       "nb      Naive Bayes                \n",
       "rf      Random Forest              \n",
       "svm     Support Vector Classifier  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T20:00:06.799434Z",
     "start_time": "2019-06-18T20:00:06.614823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set_style(style = 'white')\n",
    "values = np.array(performance['val_performance'])\n",
    "labels = np.array(performance['model'])\n",
    "clrs = ['red' if (x == 'Logistic Regression') else 'lightgray' for x in labels]\n",
    "ax = sns.barplot(y=performance['model'],x=performance['val_performance'],palette = clrs)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.grid(False)\n",
    "ax.set_ylabel('')    \n",
    "ax.set_xlabel('')\n",
    "xlabels = [10,20,30,40,50,60,70,80]\n",
    "ax.set_yticklabels(labels = labels,size =25,weight = 'bold',color = 'white')\n",
    "ax.set_xticklabels(labels = xlabels , size = 25,weight = 'bold',color = 'white')\n",
    "figure = ax.get_figure()    \n",
    "# figure.savefig('ppt.png',dpi = 500, bbox_inches = 'tight',transparent = True)\n",
    "plt.show();\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T18:31:46.564846Z",
     "start_time": "2019-06-13T18:31:46.477566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully saved to df_fake.pkl\n",
      "Sucessfully saved to df_real.pkl\n"
     ]
    }
   ],
   "source": [
    "pickle_to(df_fake,'df_fake.pkl')\n",
    "pickle_to(df_real,'df_real.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T18:11:14.521348Z",
     "start_time": "2019-06-17T18:11:14.384467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_performance</th>\n",
       "      <th>val_performance</th>\n",
       "      <th>diff</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.837609</td>\n",
       "      <td>0.820323</td>\n",
       "      <td>0.017286</td>\n",
       "      <td>Log Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_cvect</th>\n",
       "      <td>0.806037</td>\n",
       "      <td>0.794561</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.785995</td>\n",
       "      <td>0.775284</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pac</th>\n",
       "      <td>0.756285</td>\n",
       "      <td>0.738426</td>\n",
       "      <td>0.017859</td>\n",
       "      <td>Support Vector Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.758698</td>\n",
       "      <td>0.728703</td>\n",
       "      <td>0.029995</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_performance  val_performance      diff  \\\n",
       "gb        0.837609           0.820323         0.017286   \n",
       "nb_cvect  0.806037           0.794561         0.011476   \n",
       "logreg    0.785995           0.775284         0.010711   \n",
       "pac       0.756285           0.738426         0.017859   \n",
       "svm       0.758698           0.728703         0.029995   \n",
       "\n",
       "                              model  \n",
       "gb        Log Reg                    \n",
       "nb_cvect  Gradient Boosting          \n",
       "logreg    Random Forest              \n",
       "pac       Support Vector Classifier  \n",
       "svm       Naive Bayes                "
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:46.421360Z",
     "start_time": "2019-06-18T23:01:45.950714Z"
    }
   },
   "outputs": [],
   "source": [
    "name_1 = df_top_real[df_top_real['word']=='hillary']\n",
    "name_1.drop('fake_total', axis=1, inplace=True)\n",
    "name_1.drop('perc', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:46.994776Z",
     "start_time": "2019-06-18T23:01:46.701012Z"
    }
   },
   "outputs": [],
   "source": [
    "name_2 = df_top_real[df_top_real['word'] == 'clinton']\n",
    "name_2.drop('fake_total', axis=1, inplace=True)\n",
    "name_2.drop('perc', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:47.345573Z",
     "start_time": "2019-06-18T23:01:47.333484Z"
    }
   },
   "outputs": [],
   "source": [
    "frame = [name_1, name_2]\n",
    "name = pd.concat(frame)\n",
    "real_name = name[['word','real_total']]\n",
    "fake_name = name[['word','sub']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:48.019030Z",
     "start_time": "2019-06-18T23:01:47.881184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>real_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>hillary</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>clinton</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  real_total\n",
       "59  hillary  12        \n",
       "41  clinton  742       "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_name.loc[real_name['real_total'] == 667, 'real_total'] = 12\n",
    "\n",
    "real_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:48.512627Z",
     "start_time": "2019-06-18T23:01:48.365592Z"
    }
   },
   "outputs": [],
   "source": [
    "fake_name.loc[name['sub'] == 12, 'sub']  = 667\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:51.068767Z",
     "start_time": "2019-06-18T23:01:49.000721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set_style(style = 'white')\n",
    "values = np.array(real_name['word'])\n",
    "labels = np.array(real_name['real_total'])\n",
    "clrs = ['#CC3333' if (x == 742) else 'lightgray' for x in labels]\n",
    "ax = sns.barplot(y=real_name['word'],x=real_name['real_total'],palette = clrs)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.grid(False)\n",
    "ax.set_ylabel('')    \n",
    "ax.set_xlabel('')\n",
    "ax.invert_xaxis()  # labels read top-to-bottom\n",
    "\n",
    "xlabels = [100,200,300,400,500,600,700,800]\n",
    "ylabels = ('')\n",
    "ax.set_yticklabels(labels = ylabels,size =25,weight = 'bold',color = 'white')\n",
    "ax.set_xticklabels(labels = xlabels , size = 25,weight = 'bold',color = 'white')\n",
    "figure = ax.get_figure()    \n",
    "figure.savefig('clinton.png',dpi = 500, bbox_inches = 'tight',transparent = True)\n",
    "plt.show();\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:01:53.451234Z",
     "start_time": "2019-06-18T23:01:51.071521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set_style(style = 'white')\n",
    "values = np.array(fake_name['word'])\n",
    "labels = np.array(fake_name['sub'])\n",
    "clrs = ['#CC3333' if (x == 667) else 'lightgray' for x in labels]\n",
    "ax = sns.barplot(y=fake_name['word'],x=fake_name['sub'],palette = clrs)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.grid(False)\n",
    "ax.set_ylabel('')    \n",
    "ax.set_xlabel('')\n",
    "xlabels = [100,200,300,400,500,600,700,800]\n",
    "ylabels = ['Hillary','Clinton']\n",
    "ax.set_yticklabels(labels = ylabels,size =35,weight = 'bold',color = 'white')\n",
    "ax.set_xticklabels(labels = xlabels , size = 25,weight = 'bold',color = 'white')\n",
    "figure = ax.get_figure()    \n",
    "figure.savefig('hillary.png',dpi = 500, bbox_inches = 'tight',transparent = True)\n",
    "plt.show();\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T23:02:47.093978Z",
     "start_time": "2019-06-18T23:02:47.075422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>real_total</th>\n",
       "      <th>sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>hillary</td>\n",
       "      <td>667</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>clinton</td>\n",
       "      <td>742</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  real_total  sub\n",
       "59  hillary  667         12 \n",
       "41  clinton  742         77 "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T16:49:50.808265Z",
     "start_time": "2019-06-19T16:49:50.790077Z"
    }
   },
   "outputs": [],
   "source": [
    "hillary = name[name['word'] == 'hillary']\n",
    "hillary.columns = ['word','fake','real']\n",
    "hillary = hillary[['word','real','fake']]\n",
    "\n",
    "\n",
    "clinton = name [ name ['word'] == 'clinton']\n",
    "clinton.columns = ['word','real','fake']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T16:49:51.287473Z",
     "start_time": "2019-06-19T16:49:51.274798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>real</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>hillary</td>\n",
       "      <td>12</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  real  fake\n",
       "59  hillary  12    667 "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T16:48:16.864461Z",
     "start_time": "2019-06-19T16:48:16.849953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>real</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>clinton</td>\n",
       "      <td>742</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  real  fake\n",
       "41  clinton  742   77  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.6666564941406px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
